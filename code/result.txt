[prepare_data] Downloading and formatting dataset: Amod/mental_health_counseling_conversations
Downloading and preparing dataset A...mental_health_counseling_conversations...

Formatting SFT pairs: 100%|██████████| 3000/3000 [00:20<00:00, 145.21ex/s]

[prepare_data] Wrote 2,500 SFT samples → data/sft_train.jsonl
[prepare_data] Wrote 2,500 preference pairs → data/prefs.jsonl

[train_sft] Loading base model: microsoft/DialoGPT-small
Downloading model microsoft/DialoGPT-small from Huggingface...
Model loaded successfully.

Training started...
Epoch 1: 100%|██████████| 8340/8340 [00:45<00:00, 186.35 steps/s]
Epoch 1 complete! Saving model...

[train_sft] Model checkpoint saved → checkpoints/sft

[train_reward] Training reward model (simple preference → binary classification)
Training reward model...
Epoch 1: 100%|██████████| 50/50 [00:15<00:00, 45.67 steps/s]
Reward model training complete. Saving model...

[train_reward] Model checkpoint saved → checkpoints/reward

[train_ppo] RLHF with PPO – minimal demo (1 epoch)
Using PPO configuration...
Training step 1/64...
Training step 10/64...
Training step 20/64...
Training step 30/64...
Training step 40/64...
Training step 50/64...
Training step 60/64...
RLHF training complete, saving model...

[train_ppo] RLHF-tuned checkpoint → checkpoints/ppo

[evaluate] Quick empathy proxy via sentiment analysis
Generating responses for 100 prompts...
Generated responses: 100%|██████████| 100/100 [00:30<00:00, 3.33 prompts/s]

[evaluate] Positive sentiment responses: 70/100
[evaluate] Empathy ratio = 70.00%
[evaluate] Metrics written to → data/eval_metrics.txt

[one-click] Pipeline finished in 120.3 seconds! All results in 'data' & 'checkpoints' folders.
